{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting NetCDF to a Table\n",
    "\n",
    "Here the ERA5-Land soil moisture netCDF is converted to a table for eventual comparison with Wang et al. (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/processed\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "path2data = \"/Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/\"\n",
    "path2out = \"/Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/processed\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(path2out):\n",
    "    # If the folder doesn't exist, create it\n",
    "    os.makedirs(path2out)\n",
    "    print(f\"Folder created at: {path2out}\")\n",
    "else:\n",
    "    # If the folder exists, do nothing\n",
    "    print(f\"Folder already exists at: {path2out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  depth    lat  lon  depth_2  depth_3  depth_4     swvl1  \\\n",
      "0 1979-01-01    0.0 -89.75  0.0      7.0     28.0    100.0  0.181976   \n",
      "1 1979-01-01    0.0 -89.75  0.5      7.0     28.0    100.0  0.181229   \n",
      "2 1979-01-01    0.0 -89.75  1.0      7.0     28.0    100.0  0.180481   \n",
      "3 1979-01-01    0.0 -89.75  1.5      7.0     28.0    100.0  0.179733   \n",
      "4 1979-01-01    0.0 -89.75  2.0      7.0     28.0    100.0  0.178970   \n",
      "\n",
      "      swvl2     swvl3     swvl4  \n",
      "0  0.177338  0.198639  0.144913  \n",
      "1  0.177063  0.198654  0.144913  \n",
      "2  0.176743  0.198685  0.144913  \n",
      "3  0.176453  0.198700  0.144913  \n",
      "4  0.176193  0.198761  0.144913  \n",
      "(<dask_expr.expr.Scalar: expr=df.size() // 11, dtype=int64>, 11)\n"
     ]
    }
   ],
   "source": [
    "# Open the NetCDF file\n",
    "ds = xr.open_dataset(path2data + \"output_remapped.nc\")\n",
    "# Print to see structure (optional)\n",
    "#print(ds)\n",
    "\n",
    "# Select specific variables to include (e.g., swvl1, swvl2)\n",
    "selected_vars = ['swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "# Convert selected variables to a long-format DataFrame\n",
    "df = ds[selected_vars].to_dataframe().reset_index()\n",
    "\n",
    "# Convert to Dask DataFrame\n",
    "df = dd.from_pandas(df, npartitions=4)\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create weighted-average SM estimates for two depths:  \n",
    "- 0 to 100cm\n",
    "- 0 to 289cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  depth    lat  lon  depth_2  depth_3  depth_4     swvl1  \\\n",
      "0 1979-01-01    0.0 -89.75  0.0      7.0     28.0    100.0  0.181976   \n",
      "1 1979-01-01    0.0 -89.75  0.5      7.0     28.0    100.0  0.181229   \n",
      "2 1979-01-01    0.0 -89.75  1.0      7.0     28.0    100.0  0.180481   \n",
      "3 1979-01-01    0.0 -89.75  1.5      7.0     28.0    100.0  0.179733   \n",
      "4 1979-01-01    0.0 -89.75  2.0      7.0     28.0    100.0  0.178970   \n",
      "\n",
      "      swvl2     swvl3     swvl4  swvl_0_100  swvl_0_289  \n",
      "0  0.177338  0.198639  0.144913    0.192999    0.161552  \n",
      "1  0.177063  0.198654  0.144913    0.192900    0.161517  \n",
      "2  0.176743  0.198685  0.144913    0.192803    0.161484  \n",
      "3  0.176453  0.198700  0.144913    0.192700    0.161448  \n",
      "4  0.176193  0.198761  0.144913    0.192636    0.161426  \n"
     ]
    }
   ],
   "source": [
    "# Define the weights\n",
    "weights = [7, 21, 72, 189]\n",
    "\n",
    "# Multiply each variable by its corresponding weight\n",
    "df['weighted_swvl1'] = df['swvl1'] * weights[0]\n",
    "df['weighted_swvl2'] = df['swvl2'] * weights[1]\n",
    "df['weighted_swvl3'] = df['swvl3'] * weights[2]\n",
    "df['weighted_swvl4'] = df['swvl4'] * weights[3]\n",
    "\n",
    "# Calculate the weighted sum and divide by the total sum of weights\n",
    "df['swvl_0_100'] = (\n",
    "    df['weighted_swvl1'] + df['weighted_swvl2'] + df['weighted_swvl3']\n",
    ") / sum(weights[0:3])\n",
    "\n",
    "df['swvl_0_289'] = (\n",
    "    df['weighted_swvl1'] + df['weighted_swvl2'] + df['weighted_swvl3'] + df['weighted_swvl4']\n",
    ") / sum(weights)\n",
    "\n",
    "# Drop the intermediate columns (optional)\n",
    "df = df.drop(columns=['weighted_swvl1', 'weighted_swvl2', 'weighted_swvl3', 'weighted_swvl4'])\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lon    lat  yearmon  year  month  swvl_0_100  swvl_0_289     swvl1  \\\n",
      "0  0.0 -89.75  1979-01  1979      1    0.192999    0.161552  0.181976   \n",
      "1  0.5 -89.75  1979-01  1979      1    0.192900    0.161517  0.181229   \n",
      "2  1.0 -89.75  1979-01  1979      1    0.192803    0.161484  0.180481   \n",
      "3  1.5 -89.75  1979-01  1979      1    0.192700    0.161448  0.179733   \n",
      "4  2.0 -89.75  1979-01  1979      1    0.192636    0.161426  0.178970   \n",
      "\n",
      "      swvl2     swvl3     swvl4  \n",
      "0  0.177338  0.198639  0.144913  \n",
      "1  0.177063  0.198654  0.144913  \n",
      "2  0.176743  0.198685  0.144913  \n",
      "3  0.176453  0.198700  0.144913  \n",
      "4  0.176193  0.198761  0.144913  \n"
     ]
    }
   ],
   "source": [
    "#Add relevant time vars\n",
    "# Ensure the date_column is of string type\n",
    "df['time'] = df['time'].astype(str)\n",
    "\n",
    "# Extract 'yearmon' (first 7 characters: 'YYYY-MM')\n",
    "df['yearmon'] = df['time'].str[:7]\n",
    "\n",
    "# Extract 'year' (first 4 characters: 'YYYY')\n",
    "df['year'] = df['time'].str[:4]\n",
    "\n",
    "# Extract 'month' (characters at position 6-7: 'MM')\n",
    "df['month'] = df['time'].str[5:7]\n",
    "\n",
    "# Select and re-order the columns as requested\n",
    "selected_columns = [\n",
    "    'lon', 'lat', 'yearmon', 'year', 'month', \n",
    "    'swvl_0_100', 'swvl_0_289',\n",
    "    'swvl1', 'swvl2', 'swvl3', 'swvl4'\n",
    "]\n",
    "\n",
    "# Re-order the DataFrame based on the selected columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Cast columns to consistent types before merge\n",
    "df['yearmon'] = df['yearmon'].astype('string')\n",
    "df['year'] = df['year'].astype('int64')\n",
    "df['month'] = df['month'].astype('int64')\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "df['time'] = df.to_datetime(df['yearmon'], format='%Y-%m')\n",
    "\n",
    "df = df.set_index(['time', 'lat', 'lon'])\n",
    "ds = df.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the Wang et al. (2021) dataset to compare outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<dask_expr.expr.Scalar: expr=df.size() // 7, dtype=int64>, 7)\n",
      "      lon    lat  yearmon  year  month  sm_0_100  sm_0_100_rescaled\n",
      "0 -179.75  65.75  1970-01  1970      1  0.269013           0.291638\n",
      "1 -179.75  65.75  1970-02  1970      2  0.268694           0.282631\n",
      "2 -179.75  65.75  1970-03  1970      3  0.268707           0.283012\n",
      "3 -179.75  65.75  1970-04  1970      4  0.268765           0.284649\n",
      "4 -179.75  65.75  1970-05  1970      5  0.270480           0.333092\n"
     ]
    }
   ],
   "source": [
    "path2Wang = \"/Users/tejasvi/Dropbox/Database/Hydrology/Wang_2021_Soil_Moisture/processed/\"\n",
    "# Load the CSV into a DataFrame\n",
    "df_wang = pd.read_csv(path2Wang + \"sm_data_monthly_1970_2016.csv\")\n",
    "\n",
    "# Convert to Dask DataFrame\n",
    "df_wang = dd.from_pandas(df_wang, npartitions=4)\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(df_wang.shape)\n",
    "print(df_wang.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 swvl_0_100  swvl_0_289     swvl1     swvl2     swvl3  \\\n",
      "lat    lon year                                                         \n",
      "-89.75 0.0 1979    0.192999    0.161552  0.181976  0.177338  0.198639   \n",
      "           1980    0.192999    0.161552  0.181976  0.177338  0.198639   \n",
      "           1981    0.192999    0.161552  0.181976  0.177338  0.198639   \n",
      "           1982    0.192999    0.161552  0.181976  0.177338  0.198639   \n",
      "           1983    0.192999    0.161552  0.181976  0.177338  0.198639   \n",
      "\n",
      "                    swvl4  \n",
      "lat    lon year            \n",
      "-89.75 0.0 1979  0.144913  \n",
      "           1980  0.144913  \n",
      "           1981  0.144913  \n",
      "           1982  0.144913  \n",
      "           1983  0.144913  \n"
     ]
    }
   ],
   "source": [
    "#Convert both the datasets to yearly\n",
    "# Group by lat, lon, and year\n",
    "grouped = df.groupby(['lat', 'lon', 'year'])\n",
    "\n",
    "# Compute mean for all numeric columns\n",
    "df_yearly = grouped[['swvl1', 'swvl2', 'swvl3', 'swvl4', 'swvl_0_100', 'swvl_0_289']].mean()\n",
    "\n",
    "\n",
    "# Group by lat, lon, and year\n",
    "# grouped_wang = df_wang.groupby(['lat', 'lon', 'year'])\n",
    "\n",
    "# Compute mean for all numeric columns\n",
    "# df_wang_yearly = grouped_wang[['sm_0_100']].mean()\n",
    "\n",
    "print(df_yearly.head())\n",
    "\n",
    "\n",
    "# # Merge the two DataFrames on columns 'col1', 'col2', 'col3'\n",
    "# df_merged = dd.merge(df, df_wang, on=['lon', 'lat', 'yearmon', 'year', 'month'], how='inner')\n",
    "\n",
    "# # Compute the result (this triggers the actual computation and brings the data into memory)\n",
    "# df_merged = df_merged.compute()\n",
    "\n",
    "# # Preview the DataFrame\n",
    "# print(df_merged.shape)\n",
    "# print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
