{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new variables to NetCDF\n",
    "\n",
    "We create the weighted average SM estimates directly using xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/processed/\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path2data = \"/Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/\"\n",
    "path2out = \"/Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/processed/\"\n",
    "path2Wang = \"/Users/tejasvi/Dropbox/Database/Hydrology/Wang_2021_Soil_Moisture/processed/\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(path2out):\n",
    "    # If the folder doesn't exist, create it\n",
    "    os.makedirs(path2out)\n",
    "    print(f\"Folder created at: {path2out}\")\n",
    "else:\n",
    "    # If the folder exists, do nothing\n",
    "    print(f\"Folder already exists at: {path2out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 2GB\n",
      "Dimensions:       (time: 552, lon: 720, lat: 360, depth: 1, bnds: 2,\n",
      "                   depth_2: 1, depth_3: 1, depth_4: 1)\n",
      "Coordinates:\n",
      "  * time          (time) datetime64[ns] 4kB 1979-01-01 1979-02-01 ... 2024-12-01\n",
      "  * lon           (lon) float64 6kB -179.8 -179.2 -178.8 ... 178.8 179.2 179.8\n",
      "  * lat           (lat) float64 3kB -89.75 -89.25 -88.75 ... 88.75 89.25 89.75\n",
      "  * depth         (depth) float64 8B 0.0\n",
      "  * depth_2       (depth_2) float64 8B 7.0\n",
      "  * depth_3       (depth_3) float64 8B 28.0\n",
      "  * depth_4       (depth_4) float64 8B 100.0\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    depth_bnds    (depth, bnds) float64 16B ...\n",
      "    depth_2_bnds  (depth_2, bnds) float64 16B ...\n",
      "    depth_3_bnds  (depth_3, bnds) float64 16B ...\n",
      "    depth_4_bnds  (depth_4, bnds) float64 16B ...\n",
      "    swvl1         (time, depth, lat, lon) float32 572MB ...\n",
      "    swvl2         (time, depth_2, lat, lon) float32 572MB ...\n",
      "    swvl3         (time, depth_3, lat, lon) float32 572MB ...\n",
      "    swvl4         (time, depth_4, lat, lon) float32 572MB ...\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 2.1.1 (https://mpimet.mpg.de...\n",
      "    Conventions:  CF-1.6\n",
      "    institution:  European Centre for Medium-Range Weather Forecasts\n",
      "    history:      Fri Apr 04 21:15:59 2025: cdo -O -s -f nc -copy /Users/teja...\n",
      "    CDO:          Climate Data Operators version 2.1.1 (https://mpimet.mpg.de...\n"
     ]
    }
   ],
   "source": [
    "# Open the NetCDF file\n",
    "ds = xr.open_dataset(path2data + \"output_remapped.nc\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 3GB\n",
      "Dimensions:       (time: 552, lon: 720, lat: 360, depth: 1, bnds: 2,\n",
      "                   depth_2: 1, depth_3: 1, depth_4: 1)\n",
      "Coordinates:\n",
      "  * time          (time) datetime64[ns] 4kB 1979-01-01 1979-02-01 ... 2024-12-01\n",
      "  * lon           (lon) float64 6kB -179.8 -179.2 -178.8 ... 178.8 179.2 179.8\n",
      "  * lat           (lat) float64 3kB -89.75 -89.25 -88.75 ... 88.75 89.25 89.75\n",
      "  * depth         (depth) float64 8B 0.0\n",
      "  * depth_2       (depth_2) float64 8B 7.0\n",
      "  * depth_3       (depth_3) float64 8B 28.0\n",
      "  * depth_4       (depth_4) float64 8B 100.0\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    depth_bnds    (depth, bnds) float64 16B ...\n",
      "    depth_2_bnds  (depth_2, bnds) float64 16B ...\n",
      "    depth_3_bnds  (depth_3, bnds) float64 16B ...\n",
      "    depth_4_bnds  (depth_4, bnds) float64 16B ...\n",
      "    swvl1         (time, depth, lat, lon) float32 572MB ...\n",
      "    swvl2         (time, depth_2, lat, lon) float32 572MB ...\n",
      "    swvl3         (time, depth_3, lat, lon) float32 572MB ...\n",
      "    swvl4         (time, depth_4, lat, lon) float32 572MB ...\n",
      "    swvl_0_289    (time, lat, lon) float64 1GB 0.1659 0.1656 0.1654 ... 0.0 0.0\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 2.1.1 (https://mpimet.mpg.de...\n",
      "    Conventions:  CF-1.6\n",
      "    institution:  European Centre for Medium-Range Weather Forecasts\n",
      "    history:      Fri Apr 04 21:15:59 2025: cdo -O -s -f nc -copy /Users/teja...\n",
      "    CDO:          Climate Data Operators version 2.1.1 (https://mpimet.mpg.de...\n"
     ]
    }
   ],
   "source": [
    "# Remove singleton depth dimensions (drop them completely)\n",
    "swvl1 = ds['swvl1'].squeeze(drop=True)  # shape: (time, lat, lon)\n",
    "swvl2 = ds['swvl2'].squeeze(drop=True)\n",
    "swvl3 = ds['swvl3'].squeeze(drop=True)\n",
    "swvl4 = ds['swvl4'].squeeze(drop=True)\n",
    "\n",
    "# Now safely stack along a new 'depth' dimension\n",
    "stacked = xr.concat([swvl1, swvl2, swvl3, swvl4], dim='depth')\n",
    "stacked.coords['depth'] = [0, 7, 28, 100]  # optional, for metadata\n",
    "\n",
    "# Define and normalize weights\n",
    "weights = xr.DataArray([7, 21, 72, 189], dims='depth')\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# Compute weighted average\n",
    "swvl_0_289 = (stacked * weights).sum(dim='depth')\n",
    "\n",
    "# Add to original dataset\n",
    "ds['swvl_0_289'] = swvl_0_289\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 5GB\n",
      "Dimensions:       (time: 552, lon: 720, lat: 360, depth: 1, bnds: 2,\n",
      "                   depth_2: 1, depth_3: 1, depth_4: 1)\n",
      "Coordinates:\n",
      "  * time          (time) datetime64[ns] 4kB 1979-01-01 1979-02-01 ... 2024-12-01\n",
      "  * lon           (lon) float64 6kB -179.8 -179.2 -178.8 ... 178.8 179.2 179.8\n",
      "  * lat           (lat) float64 3kB -89.75 -89.25 -88.75 ... 88.75 89.25 89.75\n",
      "  * depth         (depth) float64 8B 0.0\n",
      "  * depth_2       (depth_2) float64 8B 7.0\n",
      "  * depth_3       (depth_3) float64 8B 28.0\n",
      "  * depth_4       (depth_4) float64 8B 100.0\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    depth_bnds    (depth, bnds) float64 16B ...\n",
      "    depth_2_bnds  (depth_2, bnds) float64 16B ...\n",
      "    depth_3_bnds  (depth_3, bnds) float64 16B ...\n",
      "    depth_4_bnds  (depth_4, bnds) float64 16B ...\n",
      "    swvl1         (time, depth, lat, lon) float32 572MB ...\n",
      "    swvl2         (time, depth_2, lat, lon) float32 572MB ...\n",
      "    swvl3         (time, depth_3, lat, lon) float32 572MB ...\n",
      "    swvl4         (time, depth_4, lat, lon) float32 572MB ...\n",
      "    swvl_0_289    (time, lat, lon) float64 1GB 0.1659 0.1656 0.1654 ... 0.0 0.0\n",
      "    swvl_0_100    (time, lat, lon) float64 1GB 0.2055 0.2048 0.2041 ... 0.0 0.0\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 2.1.1 (https://mpimet.mpg.de...\n",
      "    Conventions:  CF-1.6\n",
      "    institution:  European Centre for Medium-Range Weather Forecasts\n",
      "    history:      Fri Apr 04 21:15:59 2025: cdo -O -s -f nc -copy /Users/teja...\n",
      "    CDO:          Climate Data Operators version 2.1.1 (https://mpimet.mpg.de...\n"
     ]
    }
   ],
   "source": [
    "# Now safely stack along a new 'depth' dimension\n",
    "stacked = xr.concat([swvl1, swvl2, swvl3], dim='depth')\n",
    "stacked.coords['depth'] = [0, 7, 28]  # optional, for metadata\n",
    "\n",
    "# Define and normalize weights\n",
    "weights = xr.DataArray([7, 21, 72], dims='depth')\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# Compute weighted average\n",
    "swvl_0_100 = (stacked * weights).sum(dim='depth')\n",
    "\n",
    "# Add to original dataset\n",
    "ds['swvl_0_100'] = swvl_0_100\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert to yearly using xarray again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 191MB\n",
      "Dimensions:     (time: 46, lat: 360, lon: 720)\n",
      "Coordinates:\n",
      "  * lon         (lon) float64 6kB -179.8 -179.2 -178.8 ... 178.8 179.2 179.8\n",
      "  * lat         (lat) float64 3kB -89.75 -89.25 -88.75 ... 88.75 89.25 89.75\n",
      "  * time        (time) object 368B 1979-01-01 00:00:00 ... 2024-01-01 00:00:00\n",
      "Data variables:\n",
      "    swvl_0_289  (time, lat, lon) float64 95MB 0.1659 0.1656 0.1654 ... 0.0 0.0\n",
      "    swvl_0_100  (time, lat, lon) float64 95MB 0.2055 0.2048 0.2041 ... 0.0 0.0\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 2.1.1 (https://mpimet.mpg.de...\n",
      "    Conventions:  CF-1.6\n",
      "    institution:  European Centre for Medium-Range Weather Forecasts\n",
      "    history:      Fri Apr 04 21:15:59 2025: cdo -O -s -f nc -copy /Users/teja...\n",
      "    CDO:          Climate Data Operators version 2.1.1 (https://mpimet.mpg.de...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/knp134qs6wqgkbfwmwcrs8vw0000gn/T/ipykernel_8014/411229372.py:10: DeprecationWarning: cftime_range() is deprecated, please use xarray.date_range(..., use_cftime=True) instead.\n",
      "  ds_yearly['time'] = xr.cftime_range(start=str(ds_yearly.time.values[0]), periods=len(ds_yearly.time), freq='YS')\n"
     ]
    }
   ],
   "source": [
    "# Select only the variables you're interested in\n",
    "ds_sel = ds[[\"swvl_0_289\", \"swvl_0_100\"]]\n",
    "\n",
    "# Group by year and compute the mean\n",
    "ds_yearly = ds_sel.groupby(\"time.year\").mean(\"time\")\n",
    "\n",
    "# Optionally rename 'year' dimension back to 'time' with datetime index\n",
    "# If you want real datetime timestamps:\n",
    "ds_yearly = ds_yearly.rename({'year': 'time'})\n",
    "ds_yearly['time'] = xr.cftime_range(start=str(ds_yearly.time.values[0]), periods=len(ds_yearly.time), freq='YS')\n",
    "\n",
    "# Convert longitudes from [0, 360] to [-180, 180] (To match Wang et al./fishnet)\n",
    "ds_yearly['lon'] = ((ds_yearly['lon'] + 180) % 360) - 180\n",
    "\n",
    "# Sort the dataset along the new lon axis (important!)\n",
    "ds_yearly = ds_yearly.sortby('lon')\n",
    "\n",
    "print(ds_yearly)\n",
    "\n",
    "# Save to NetCDF\n",
    "#ds_yearly.to_netcdf(path2out + \"swvl_yearly_avg.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the yearly as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time    lat     lon  swvl_0_289  swvl_0_100\n",
      "0  1979-01-01 00:00:00 -89.75 -179.75    0.165884    0.205519\n",
      "1  1979-01-01 00:00:00 -89.75 -179.25    0.165637    0.204805\n",
      "2  1979-01-01 00:00:00 -89.75 -178.75    0.165387    0.204084\n",
      "3  1979-01-01 00:00:00 -89.75 -178.25    0.165140    0.203368\n",
      "4  1979-01-01 00:00:00 -89.75 -177.75    0.164892    0.202652\n",
      "(<dask_expr.expr.Scalar: expr=df.size() // 5, dtype=int64>, 5)\n"
     ]
    }
   ],
   "source": [
    "# Select specific variables to include (e.g., swvl1, swvl2)\n",
    "selected_vars = [\"swvl_0_289\", \"swvl_0_100\"]\n",
    "\n",
    "# Convert selected variables to a long-format DataFrame\n",
    "df = ds_yearly[selected_vars].to_dataframe().reset_index()\n",
    "\n",
    "# Convert to Dask DataFrame\n",
    "df = dd.from_pandas(df, npartitions=4)\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          lon    lat  yearmon  year  swvl_0_100  swvl_0_289\n",
      "50400 -179.75 -54.75  1979-01  1979         0.0         0.0\n",
      "50401 -179.25 -54.75  1979-01  1979         0.0         0.0\n",
      "50402 -178.75 -54.75  1979-01  1979         0.0         0.0\n",
      "50403 -178.25 -54.75  1979-01  1979         0.0         0.0\n",
      "50404 -177.75 -54.75  1979-01  1979         0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# Ensure the date_column is of string type\n",
    "df['time'] = df['time'].astype(str)\n",
    "\n",
    "# Extract 'yearmon' (first 7 characters: 'YYYY-MM')\n",
    "df['yearmon'] = df['time'].str[:7]\n",
    "\n",
    "# Extract 'year' (first 4 characters: 'YYYY')\n",
    "df['year'] = df['time'].str[:4]\n",
    "\n",
    "# Extract 'month' (characters at position 6-7: 'MM')\n",
    "#df['month'] = df['time'].str[5:7]\n",
    "\n",
    "# Select and re-order the columns as requested\n",
    "selected_columns = [\n",
    "    'lon', 'lat', 'yearmon', 'year',\n",
    "    'swvl_0_100', 'swvl_0_289'\n",
    "]\n",
    "\n",
    "# Re-order the DataFrame based on the selected columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Filter latitude to between -54.75 and 78.75\n",
    "df = df[(df['lat'] >= -54.75) & (df['lat'] <= 78.75)]\n",
    "\n",
    "print(df.head())#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file path: /Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/processed/ERA5_land_sm_data_05deg_1979_2024.csv\n",
      "File saved at: /Users/tejasvi/Dropbox/Database/Hydrology/era5_land_soil_moisture/processed/ERA5_land_sm_data_05deg_1979_2024.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the full file path with the correct file name\n",
    "output_file = os.path.join(output_dir, \"ERA5_land_sm_data_05deg_1979_2024.csv\")\n",
    "\n",
    "# Check the final output file path\n",
    "print(f\"Output file path: {output_file}\")\n",
    "\n",
    "# Save to CSV\n",
    "#df_pandas = df.compute()  # Convert to Pandas DataFrame\n",
    "#df_pandas.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"File saved at: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Wang Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<dask_expr.expr.Scalar: expr=df.size() // 7, dtype=int64>, 7)\n",
      "      lon    lat  yearmon  year  month  sm_0_100  sm_0_100_rescaled\n",
      "0 -179.75  65.75  1970-01  1970      1  0.269013           0.291638\n",
      "1 -179.75  65.75  1970-02  1970      2  0.268694           0.282631\n",
      "2 -179.75  65.75  1970-03  1970      3  0.268707           0.283012\n",
      "3 -179.75  65.75  1970-04  1970      4  0.268765           0.284649\n",
      "4 -179.75  65.75  1970-05  1970      5  0.270480           0.333092\n",
      "<bound method FrameBase.min of Dask Series Structure:\n",
      "npartitions=4\n",
      "0           float64\n",
      "7953387         ...\n",
      "15906774        ...\n",
      "23860161        ...\n",
      "31813547        ...\n",
      "Dask Name: getitem, 2 expressions\n",
      "Expr=df['lon']> <bound method FrameBase.max of Dask Series Structure:\n",
      "npartitions=4\n",
      "0           float64\n",
      "7953387         ...\n",
      "15906774        ...\n",
      "23860161        ...\n",
      "31813547        ...\n",
      "Dask Name: getitem, 2 expressions\n",
      "Expr=df['lon']>\n"
     ]
    }
   ],
   "source": [
    "path2Wang = \"/Users/tejasvi/Dropbox/Database/Hydrology/Wang_2021_Soil_Moisture/processed/\"\n",
    "# Load the CSV into a DataFrame\n",
    "df_wang = pd.read_csv(path2Wang + \"sm_data_monthly_1970_2016.csv\")\n",
    "\n",
    "# Convert to Dask DataFrame\n",
    "df_wang = dd.from_pandas(df_wang, npartitions=4)\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(df_wang.shape)\n",
    "print(df_wang.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 4GB\n",
      "Dimensions:            (time: 564, lat: 268, lon: 679)\n",
      "Coordinates:\n",
      "  * time               (time) datetime64[ns] 5kB 1970-01-01 ... 2016-12-01\n",
      "  * lat                (lat) float64 2kB -54.75 -54.25 -53.75 ... 78.25 78.75\n",
      "  * lon                (lon) float64 5kB -179.8 -179.2 -178.8 ... 179.2 179.8\n",
      "Data variables:\n",
      "    yearmon            (time, lat, lon) object 821MB nan nan nan ... nan nan nan\n",
      "    year               (time, lat, lon) float64 821MB nan nan nan ... nan nan\n",
      "    month              (time, lat, lon) float64 821MB nan nan nan ... nan nan\n",
      "    sm_0_100           (time, lat, lon) float64 821MB nan nan nan ... nan nan\n",
      "    sm_0_100_rescaled  (time, lat, lon) float64 821MB nan nan nan ... nan nan\n"
     ]
    }
   ],
   "source": [
    "# Assume your Dask DataFrame is called df\n",
    "# Step 1: Create a proper time column\n",
    "df_wang['time'] = dd.to_datetime(df_wang['year'].astype(str) + '-' + df_wang['month'].astype(str).str.zfill(2) + '-01')\n",
    "\n",
    "# Step 2: Compute to Pandas\n",
    "pdf = df_wang.compute()\n",
    "\n",
    "# Step 3: Convert to xarray using from_dataframe\n",
    "ds_wang = xr.Dataset.from_dataframe(pdf.set_index(['time', 'lat', 'lon']))\n",
    "\n",
    "print(ds_wang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 68MB\n",
      "Dimensions:   (time: 47, lat: 268, lon: 679)\n",
      "Coordinates:\n",
      "  * lat       (lat) float64 2kB -54.75 -54.25 -53.75 ... 77.75 78.25 78.75\n",
      "  * lon       (lon) float64 5kB -179.8 -179.2 -178.8 ... 178.8 179.2 179.8\n",
      "  * time      (time) object 376B 1970-01-01 00:00:00 ... 2016-01-01 00:00:00\n",
      "Data variables:\n",
      "    sm_0_100  (time, lat, lon) float64 68MB nan nan nan nan ... nan nan nan nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/knp134qs6wqgkbfwmwcrs8vw0000gn/T/ipykernel_94903/2330183468.py:13: DeprecationWarning: cftime_range() is deprecated, please use xarray.date_range(..., use_cftime=True) instead.\n",
      "  ds_yearly['time'] = xr.cftime_range(start=str(ds_yearly.time.values[0]), periods=len(ds_yearly.time), freq='YS')\n"
     ]
    }
   ],
   "source": [
    "# Assuming your xarray dataset is called ds\n",
    "\n",
    "# Select only the variables you're interested in\n",
    "ds_sel = ds_wang[[\"sm_0_100\"]]\n",
    "\n",
    "# Step 1: Group by year and calculate the mean\n",
    "ds_yearly = ds_sel.groupby(\"time.year\").mean(\"time\")\n",
    "\n",
    "# Step 2: Optionally, you can rename the 'year' coordinate back to 'time' with datetime values\n",
    "ds_yearly = ds_yearly.rename({'year': 'time'})\n",
    "\n",
    "# Create the corresponding datetime values for each year\n",
    "ds_yearly['time'] = xr.cftime_range(start=str(ds_yearly.time.values[0]), periods=len(ds_yearly.time), freq='YS')\n",
    "\n",
    "# Step 3: Export the result to NetCDF\n",
    "ds_yearly.to_netcdf(path2Wang + \"yearly_avg.nc\")\n",
    "\n",
    "print(ds_yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
